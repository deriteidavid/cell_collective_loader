{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell Collective loader\n",
    "\n",
    "This is a notebook that downloads all models uploaded to the [Cell Collective](https://research.cellcollective.org/) and creates local [SBML](https://en.wikipedia.org/wiki/SBML)  and [BooleanNet](https://github.com/ialbert/booleannet) files. It also collects all molecular species in all models in a table (dataframe) with associated models, links, etc.\n",
    "\n",
    "You will need the following packages:\n",
    "\n",
    "* Colomoto Jupyter [https://github.com/colomoto/colomoto-jupyter]\n",
    "* GINsim python [https://github.com/GINsim/GINsim-python]\n",
    "* Pandas [https://pandas.pydata.org/getting_started.html]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cellcollective #https://github.com/colomoto/colomoto-jupyter\n",
    "import biolqm #https://github.com/GINsim/GINsim-python\n",
    "import requests\n",
    "import json\n",
    "from urllib.request import urlretrieve\n",
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a simple function creating a permanent local file from the retrieved model file\n",
    "def download_local(url, path, model_id, suffix='sbml'):\n",
    "    filename = path+str(model_id)+'.'+suffix\n",
    "    filename, _ = urlretrieve(url, filename=filename)\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sbmls_path='sbmls/'\n",
    "boolean_models_path='boolean_models/'\n",
    "\n",
    "#if they don't exist we create them\n",
    "import os\n",
    "if not os.path.exists(sbmls_path):\n",
    "    os.makedirs(sbmls_path)\n",
    "if not os.path.exists(boolean_models_path):\n",
    "    os.makedirs(boolean_models_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the model ids from the cell collective website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "  \"User-Agent\": \"Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/72.0.3626.119 Safari/537.36\"\n",
    "}\n",
    "\n",
    "url = \"https://research.cellcollective.org/api/model\"\n",
    "\n",
    "r = requests.get(url, headers=headers)\n",
    "data = r.json()\n",
    "model_name_dict={}\n",
    "for i in range(len(data['data'])):\n",
    "    if 'model' in data['data'][i].keys():\n",
    "        model_name_dict[data['data'][i]['model']['id']]=data['data'][i]['model']['name']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(model_name_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is manually curated list from which all model ids will be skipped from downloading and all subsequent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exception_list=[126843,3511,118235,15088,36604]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The download script checks the sbml folder for models already downloaded and skips them (it still downloads newly uploaded models). If set this to True to ignore the contents of the sbml folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_all_again=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "species_dict={}\n",
    "df=pd.DataFrame()\n",
    "\n",
    "for model_id in model_name_dict:\n",
    "    print('Checking',model_id)\n",
    "    if model_id in exception_list:\n",
    "        print('Model id is in exception list')\n",
    "        continue\n",
    "    downloaded_model_paths=glob.glob(sbmls_path+'*.sbml')\n",
    "    if not download_all_again:\n",
    "        downloaded_models=[int(i.split('/')[-1].split('.')[0]) for i in downloaded_model_paths]\n",
    "    else:\n",
    "        downloaded_models=[]\n",
    "\n",
    "    if model_id not in downloaded_models:\n",
    "        url='https://research.cellcollective.org/api/model/%d/export/version/1?type=SBML'%model_id\n",
    "        try:\n",
    "            sbml = cellcollective.load(url)\n",
    "        except Exception as e:\n",
    "            print(model_id, str(e))\n",
    "            continue\n",
    "        model_name=sbml.dom.getElementsByTagName('model')[0].getAttribute('name')\n",
    "        print(model_name)\n",
    "\n",
    "        #I download the file again locally because the colomoto biolqm.load does not work with the temporal download initiated by the the cellcollective script.\n",
    "        filename = download_local(url,sbmls_path,model_id)\n",
    "        sbml.localfile=filename\n",
    "        #save to boolean net\n",
    "        lqm = cellcollective.to_biolqm(sbml)\n",
    "        biolqm.save(lqm, \"%s%d_%s.booleannet\"%(boolean_models_path,model_id,model_name.replace(' ','_')), \"booleannet\")\n",
    "\n",
    "    sbml = cellcollective.load(sbmls_path+str(model_id)+'.sbml')\n",
    "    for s in sbml.species:\n",
    "        if sbml.species_uniprotkb(s)!=None:\n",
    "            uniprot=sbml.species_uniprotkb(s).data\n",
    "        else:\n",
    "            uniprot=None\n",
    "            \n",
    "        row={'species':s.strip(),\n",
    "             'model_id':model_id,\n",
    "             'model_name':model_name_dict[model_id],\n",
    "             'uniprot_info':uniprot,\n",
    "             'ncbi_gene_info':sbml.species_ncbi_gene(s),\n",
    "             'link_to_model':'https://research.cellcollective.org/?dashboard=true#module/%d:1/'%model_id}\n",
    "        df=df.append(row,ignore_index=True)\n",
    "        if s in species_dict:\n",
    "            species_dict[s].append(model_id)\n",
    "        else:\n",
    "            species_dict[s]=[model_id]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a dictionary mapping molecular species to model_ids of models containing them\n",
    "print(species_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There exists several python interfaces to programmatically query information from these databases:\n",
    "- using NBCI Gene ID: https://github.com/biocommons/eutils\n",
    "- using UniProt ID: https://github.com/jdrudolph/uniprot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reindex(['species','model_id','model_name','link_to_model','uniprot_info','ncbi_gene_info'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('species')\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_excel('cell_collective_species_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
